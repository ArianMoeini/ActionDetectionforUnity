{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Import and Install Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install tensorflow==2.4.1 tensorflow-gpu==2.4.1 opencv-python mediapipe sklearn matplotlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import os\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyzed.sl as sl"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Setup Folders for Collection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Path for exported data, numpy arrays\n",
    "DATA_PATH = os.path.join('MP_Data') \n",
    "\n",
    "# Actions that we try to detect\n",
    "actions = np.array(['boxing', 'notFighting', 'kick'])\n",
    "\n",
    "# Thirty videos worth of data\n",
    "no_sequences = 30\n",
    "\n",
    "# Videos are going to be 30 frames in length\n",
    "sequence_length = 30\n",
    "\n",
    "# Folder start\n",
    "start_folder = 30"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create the folder DATA_PATH if it does not exist and make all the actions as subfolders\n",
    "for action in actions:\n",
    "    for sequence in range(no_sequences):\n",
    "        try:\n",
    "            os.makedirs(os.path.join(DATA_PATH, action, str(sequence)))\n",
    "        except:\n",
    "            pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for action in actions: \n",
    "    dirmax = np.max(np.array(os.listdir(os.path.join(DATA_PATH, action))).astype(int))\n",
    "    for sequence in range(1,no_sequences+1):\n",
    "        try: \n",
    "            os.makedirs(os.path.join(DATA_PATH, action, str(dirmax+sequence)))\n",
    "        except:\n",
    "            pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Setup ZED2i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def draw_skeleton(frame, keypoint_2d):\n",
    "    # Define connections between keypoints if not , e.g., [(0, 1), (1, 2), ...]\n",
    "    # Defines keypoints for Zed2i SDK\n",
    "    skeleton_pairs = [\n",
    "        # Spine\n",
    "        (0, 1), (1, 2), (2, 3), (3, 4),\n",
    "        # Head\n",
    "        (4, 5), (5, 6), (5, 7), (6, 8), (7, 9),\n",
    "        # Arms\n",
    "        (4, 10), (10, 12), (12, 14), (14, 16),  # Left arm\n",
    "        (4, 11), (11, 13), (13, 15), (15, 17),  # Right arm\n",
    "        # Legs\n",
    "        (0, 18), (18, 20), (20, 22), (22, 24), (22, 26), (22, 28),  # Left leg\n",
    "        (0, 19), (19, 21), (21, 23), (23, 25), (23, 27), (23, 29),  # Right leg\n",
    "        # Fingers (only showing the first and last joint for brevity)\n",
    "        (16, 30), (16, 32), (16, 34), (16, 36),  # Left hand fingers\n",
    "        (17, 31), (17, 33), (17, 35), (17, 37),  # Right hand fingers\n",
    "    ]\n",
    "\n",
    "\n",
    "    for start, end in skeleton_pairs:\n",
    "        start_point = tuple(map(int, keypoint_2d[start]))\n",
    "        end_point = tuple(map(int, keypoint_2d[end]))\n",
    "\n",
    "        # Draw lines for bones\n",
    "        cv2.line(frame, start_point, end_point, (0, 255, 0), 2)\n",
    "\n",
    "        # Draw circles for joints\n",
    "        cv2.circle(frame, start_point, 3, (0, 0, 255), -1)\n",
    "        cv2.circle(frame, end_point, 3, (0, 0, 255), -1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Collect Keypoint Values for Training and Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "def write_keypoints_to_csv(action_class, keypoints, filename):\n",
    "    #Create a header for the CSV file\n",
    "    header = ['class']\n",
    "    for val in range(1, len(keypoints) + 1):\n",
    "        header.append(f\"x{val}\")\n",
    "        header.append(f\"y{val}\")\n",
    "\n",
    "    # Flatten the keypoints list\n",
    "    flat_keypoints = [coord for kp in keypoints for coord in kp]\n",
    "\n",
    "    print(flat_keypoints)\n",
    "    # Open the CSV file for writing and appending\n",
    "    with open(filename, mode='a', newline='') as file:\n",
    "        csv_writer = csv.writer(file, delimiter=';', quotechar='\"', quoting=csv.QUOTE_MINIMAL)\n",
    "        \n",
    "        # Write the header only once at the beginning\n",
    "        if file.tell() == 0:\n",
    "            csv_writer.writerow(header)\n",
    "        \n",
    "        # Write the keypoints, prefixed with the action class\n",
    "        row = [action_class] + flat_keypoints\n",
    "        csv_writer.writerow(row)\n",
    "\n",
    "\n",
    "def write_keypoints_to_csv3D(action_class, keypoints, filename):\n",
    "    #Create a header for the CSV file\n",
    "    header = ['class']\n",
    "    for val in range(1, len(keypoints) + 1):\n",
    "        header.append(f\"x{val}\")\n",
    "        header.append(f\"y{val}\")\n",
    "        header.append(f\"z{val}\")\n",
    "\n",
    "    # Flatten the keypoints list\n",
    "    flat_keypoints = [coord for kp in keypoints for coord in kp]\n",
    "\n",
    "    print(flat_keypoints)\n",
    "    # Open the CSV file for writing and appending\n",
    "    with open(filename, mode='a', newline='') as file:\n",
    "        csv_writer = csv.writer(file, delimiter=';', quotechar='\"', quoting=csv.QUOTE_MINIMAL)\n",
    "        \n",
    "        # Write the header only once at the beginning\n",
    "        if file.tell() == 0:\n",
    "            csv_writer.writerow(header)\n",
    "        \n",
    "        # Write the keypoints, prefixed with the action class\n",
    "        row = [action_class] + flat_keypoints\n",
    "        csv_writer.writerow(row)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "actions = np.array(['boxing', 'notFighting', 'kick'])\n",
    "no_sequences = 30\n",
    "sequence_length = 30\n",
    "DATA_PATH = os.path.join('MP_Data') \n",
    "\n",
    "\n",
    "for actionses in actions:\n",
    "    for sequence in range(0, no_sequences + 1):\n",
    "        try:\n",
    "            os.makedirs(os.path.join(DATA_PATH, actionses, str(sequence)))\n",
    "        except:\n",
    "            pass\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " # Create a Camera object\n",
    "zed = sl.Camera()\n",
    "\n",
    "# Create a InitParameters object and set configuration parameters\n",
    "init_params = sl.InitParameters()\n",
    "#init_params.camera_resolution = sl.RESOLUTION.HD720  # Use HD720 video mode\n",
    "init_params.depth_mode = sl.DEPTH_MODE.PERFORMANCE\n",
    "init_params.coordinate_units = sl.UNIT.METER\n",
    "init_params.sdk_verbose = 1\n",
    "\n",
    "init_params.camera_resolution = sl.RESOLUTION.HD1080\n",
    "init_params.camera_fps = 30\n",
    "\n",
    "\n",
    "\n",
    "# Open the camera\n",
    "err = zed.open(init_params)\n",
    "if err != sl.ERROR_CODE.SUCCESS:\n",
    "    print(\"Camera Open : \"+repr(err)+\". Exit program.\")\n",
    "    exit()\n",
    "\n",
    "body_params = sl.BodyTrackingParameters()\n",
    "# Different model can be chosen, optimizing the runtime or the accuracy\n",
    "body_params.detection_model = sl.BODY_TRACKING_MODEL.HUMAN_BODY_FAST\n",
    "body_params.enable_tracking = True\n",
    "body_params.image_sync = True\n",
    "body_params.enable_segmentation = False\n",
    "# Optimize the person joints position, requires more computations\n",
    "body_params.enable_body_fitting = True\n",
    "body_params.body_format = sl.BODY_FORMAT.BODY_38\n",
    "\n",
    "if body_params.enable_tracking:\n",
    "    positional_tracking_param = sl.PositionalTrackingParameters()\n",
    "    # positional_tracking_param.set_as_static = True\n",
    "    positional_tracking_param.set_floor_as_origin = True\n",
    "    zed.enable_positional_tracking(positional_tracking_param)\n",
    "\n",
    "print(\"Body tracking: Loading Module...\")\n",
    "\n",
    "err = zed.enable_body_tracking(body_params)\n",
    "if err != sl.ERROR_CODE.SUCCESS:\n",
    "    print(\"Enable Body Tracking : \"+repr(err)+\". Exit program.\")\n",
    "    zed.close()\n",
    "    exit()\n",
    "bodies = sl.Bodies()\n",
    "body_runtime_param = sl.BodyTrackingRuntimeParameters()\n",
    "# For outdoor scene or long range, the confidence should be lowered to avoid missing detections (~20-30)\n",
    "# For indoor scene or closer range, a higher confidence limits the risk of false positives and increase the precision (~50+)\n",
    "body_runtime_param.detection_confidence_threshold = 40\n",
    "\n",
    "\n",
    "cv2.namedWindow(\"ZED Body Tracking\", cv2.WINDOW_NORMAL)\n",
    "image = sl.Mat()\n",
    "i = 0 \n",
    "\n",
    "cap = cv2.VideoCapture(0)\n",
    "# NEW LOOP\n",
    "# Loop through actions\n",
    "for action in actions:\n",
    "    # Loop through sequences aka videos\n",
    "    for sequence in range(no_sequences):\n",
    "        # Loop through video length aka sequence length\n",
    "        for frame_num in range(sequence_length):\n",
    "            \n",
    "            if sequence == 0:\n",
    "                #go to next sequence\n",
    "                continue\n",
    "            if zed.grab() == sl.ERROR_CODE.SUCCESS:\n",
    "                \n",
    "                zed.retrieve_image(image, sl.VIEW.LEFT)  # Get the image\n",
    "                frame = image.get_data()  # Convert to OpenCV format\n",
    "                err = zed.retrieve_bodies(bodies, body_runtime_param)\n",
    "                if bodies.is_new:\n",
    "                    body_array = bodies.body_list\n",
    "\n",
    "                    if len(body_array) > 0:\n",
    "\n",
    "                        #make a 30 seconds counter before starting to record\n",
    "                        for body in body_array:\n",
    "\n",
    "                            body = body_array[0]\n",
    "                            keypoint_2d = body.keypoint_2d\n",
    "                            keypoint_3d = body.keypoint\n",
    "                            draw_skeleton(frame, keypoint_2d)\n",
    "                            print(keypoint_2d[15])\n",
    "                            cv2.imshow('OpenCV Feed', frame)\n",
    "\n",
    "                            # NEW Apply wait logic\n",
    "                            if frame_num == 0: \n",
    "                                cv2.putText(frame, 'STARTING COLLECTION', (120,200), \n",
    "                                        cv2.FONT_HERSHEY_SIMPLEX, 1, (0,255, 0), 4, cv2.LINE_AA)\n",
    "                                cv2.putText(frame, 'Collecting frames for {} Video Number {}'.format(action, sequence), (15,12), \n",
    "                                        cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 0, 255), 1, cv2.LINE_AA)\n",
    "                                # Show to screen\n",
    "                                cv2.imshow('OpenCV Feed', frame)\n",
    "                                cv2.waitKey(5000)\n",
    "                            else: \n",
    "                                cv2.putText(frame, 'Collecting frames for {} Video Number {}'.format(action, sequence), (15,12), \n",
    "                                        cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 0, 255), 1, cv2.LINE_AA)\n",
    "                                # Show to screen\n",
    "                                cv2.imshow('OpenCV Feed', frame)\n",
    "                             \n",
    "                             # NEW Export keypoints\n",
    "                            write_keypoints_to_csv3D(action, keypoint_2d, 'keypoints.csv')\n",
    "                            npy_path = os.path.join(DATA_PATH, action, str(sequence), str(frame_num))\n",
    "                            np.save(npy_path, keypoint_2d)\n",
    "\n",
    "                            # Break gracefully\n",
    "                            if cv2.waitKey(10) & 0xFF == ord('q'):\n",
    "                                break\n",
    "                    \n",
    "    cap.release()\n",
    "    cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create a header for the CSV file\n",
    "header = ['class']\n",
    "for val in range(1, len(keypoint_3d) + 1):\n",
    "    print(val)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. Preprocess Data and Create Labels and Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.utils import to_categorical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_map = {label:num for num, label in enumerate(actions)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sequences, labels = [], []\n",
    "for action in actions:\n",
    "    for sequence in range(no_sequences):\n",
    "        window = []\n",
    "        if sequence == 0:\n",
    "            continue\n",
    "        for frame_num in range(sequence_length):\n",
    "            res = np.load(os.path.join(DATA_PATH, action, str(sequence), \"{}.npy\".format(frame_num)))\n",
    "            window.append(res)\n",
    "        sequences.append(window)\n",
    "        labels.append(label_map[action])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.array(labels).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.array(sequences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = X.reshape((X.shape[0], X.shape[1], -1))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = to_categorical(labels).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.05)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Reshape data for scaling\n",
    "nsamples, nx, ny = X_train.shape\n",
    "X_train_reshaped = X_train.reshape((nsamples*nx, ny))\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train_reshaped)\n",
    "\n",
    "# Reshape data back to original shape\n",
    "X_train_scaled = X_train_scaled.reshape((nsamples, nx, ny))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6. Build and Train LSTM Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Dense, Dropout\n",
    "from tensorflow.keras.callbacks import TensorBoard\n",
    "from tensorflow.keras.regularizers import l2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_dir = os.path.join(\"Logs\")\n",
    "tb_callback= TensorBoard(log_dir=log_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(LSTM(32, return_sequences=False, input_shape=(30,76), activation='tanh',\n",
    "               kernel_regularizer=l2(0.01)))  # L2 regularization\n",
    "model.add(Dropout(0.5))  # Dropout\n",
    "model.add(Dense(16, activation=\"relu\"))\n",
    "#model.add(Dropout(0.5))  # Dropout\n",
    "model.add(Dense(actions.shape[0], activation=\"softmax\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.optimizers import Adam\n",
    "\n",
    "optimizer = Adam(learning_rate=0.00007, clipnorm=1.0)\n",
    "\n",
    "model.compile(optimizer=optimizer, loss='categorical_crossentropy', metrics=['categorical_accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=100, mode='min', verbose=1)\n",
    "\n",
    "model.fit(X_train, y_train, epochs=1000, callbacks=[tb_callback, early_stopping], validation_split=0.1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Make a prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.predict(X_test)[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "actions[np.argmax(model.predict(X_test)[3])]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "actions[np.argmax(y_test[3])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('mainModel.h5')\n",
    "del model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 7. Evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.load_weights('mainModel.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lstm_layer = model.layers[0]\n",
    "\n",
    "# Extract all weights from the LSTM layer\n",
    "weights = lstm_layer.get_weights()  # Returns a list of numpy arrays\n",
    "\n",
    "# LSTM weights include input, recurrent (hidden), and biases\n",
    "# weights[0] are input weights, [1] are recurrent weights, [2] are biases\n",
    "\n",
    "# Input weights to the LSTM for skeleton point k\n",
    "input_weights_k = weights[0][:, 5]\n",
    "\n",
    "# Output or analyze the extracted weights\n",
    "print(\"Input weights for skeleton point k:\", input_weights_k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_accuracy(predictions, labels):\n",
    "    # Assuming both inputs are numpy arrays and labels are one-hot encoded\n",
    "    predicted_classes = np.argmax(predictions, axis=-1)\n",
    "    true_classes = np.argmax(labels, axis=-1)\n",
    "    accuracy = np.mean(predicted_classes == true_classes)\n",
    "    return accuracy\n",
    "\n",
    "# Predicting on original data\n",
    "original_predictions = model.predict(X_test)\n",
    "original_accuracy = compute_accuracy(original_predictions, y_test)\n",
    "print(original_accuracy)\n",
    "\n",
    "num_features = X_test.shape[2]  # Number of skeleton points\n",
    "importances = np.zeros(num_features)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Normalized Keypoint Importance for Actions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "\n",
    "# Filter out the samples for the 'boxing' action\n",
    "boxing_index = np.where(np.argmax(y, axis=1) == label_map['boxing'])[0]\n",
    "X_boxing = X[boxing_index]\n",
    "y_boxing = y[boxing_index]\n",
    "\n",
    "\n",
    "# Predict with the original 'boxing' test set\n",
    "original_predictions = model.predict(X_boxing)\n",
    "original_pred_labels = np.argmax(original_predictions, axis=1)\n",
    "y_boxing_labels = np.argmax(y_boxing, axis=1)\n",
    "original_accuracy = accuracy_score(y_boxing_labels, original_pred_labels)\n",
    "\n",
    "# Store the accuracy change for 'boxing'\n",
    "accuracy_changes_boxing = []\n",
    "\n",
    "# Perform feature ablation for 'boxing'\n",
    "for i in range(76):  # Loop over each feature\n",
    "    X_ablated = X_boxing.copy()\n",
    "    X_ablated[:, :, i] = 0  # Zero out the feature\n",
    "    ablated_predictions = model.predict(X_ablated)\n",
    "    ablated_pred_labels = np.argmax(ablated_predictions, axis=1)\n",
    "    change_in_accuracy = original_accuracy - accuracy_score(y_boxing_labels, ablated_pred_labels)\n",
    "    accuracy_changes_boxing.append(change_in_accuracy)\n",
    "\n",
    "# Calculate and normalize the importance for 'boxing'\n",
    "keypoint_importance_boxing = np.zeros(38)\n",
    "for i in range(0, 76, 2):\n",
    "    keypoint_index = i // 2\n",
    "    keypoint_importance_boxing[keypoint_index] = accuracy_changes_boxing[i] + accuracy_changes_boxing[i + 1]\n",
    "keypoint_importance_boxing = np.abs(keypoint_importance_boxing)\n",
    "normalized_keypoint_importance_boxing = keypoint_importance_boxing / np.sum(keypoint_importance_boxing)\n",
    "\n",
    "# Plot the importance for 'boxing'\n",
    "plt.figure(figsize=(15, 5))\n",
    "plt.bar(range(38), normalized_keypoint_importance_boxing)\n",
    "plt.title('Normalized Keypoint Importance for boxing Action')\n",
    "plt.xlabel('Keypoint Index')\n",
    "plt.ylabel('Normalized Importance')\n",
    "plt.xticks(range(38))  # Add keypoint names if available\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Normalized Keypoint Importance for model based on testset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict with the original test set\n",
    "original_predictions = model.predict(X_test)\n",
    "# Convert one-hot encoded predictions to label indices\n",
    "original_pred_labels = np.argmax(original_predictions, axis=1)\n",
    "# Convert one-hot encoded true labels to label indices\n",
    "y_test_labels = np.argmax(y_test, axis=1)\n",
    "# Calculate the original accuracy\n",
    "original_accuracy = accuracy_score(y_test_labels, original_pred_labels)\n",
    "\n",
    "# Store the accuracy change\n",
    "accuracy_changes = []\n",
    "\n",
    "# Perform feature ablation\n",
    "for i in range(76):  # Loop over each feature (38 keypoints * 2 for x and y)\n",
    "    # Copy X_test to not alter original data\n",
    "    X_ablated = X_test.copy()\n",
    "    \n",
    "    # Zero out the feature across all samples and time steps\n",
    "    X_ablated[:, :, i] = 0\n",
    "    \n",
    "    # Predict with the ablated test set\n",
    "    ablated_predictions = model.predict(X_ablated)\n",
    "    # Convert one-hot encoded predictions to label indices\n",
    "    ablated_pred_labels = np.argmax(ablated_predictions, axis=1)\n",
    "    \n",
    "    # Calculate the change in accuracy\n",
    "    change_in_accuracy = original_accuracy - accuracy_score(y_test_labels, ablated_pred_labels)\n",
    "    accuracy_changes.append(change_in_accuracy)\n",
    "\n",
    "# Initialize an array for summed importance of keypoints\n",
    "keypoint_importance = np.zeros(38)\n",
    "\n",
    "# Sum the importance of x and y for each keypoint\n",
    "for i in range(0, 76, 2):  # Increment by 2 since we are processing pairs (x, y)\n",
    "    keypoint_index = i // 2  # Integer division to get keypoint index\n",
    "    keypoint_importance[keypoint_index] = accuracy_changes[i] + accuracy_changes[i + 1]\n",
    "\n",
    "# Normalize the importance values\n",
    "normalized_keypoint_importance = keypoint_importance / np.sum(keypoint_importance)\n",
    "\n",
    "# Plot the importance of keypoints\n",
    "plt.figure(figsize=(15, 5))\n",
    "plt.bar(range(len(normalized_keypoint_importance)), normalized_keypoint_importance)\n",
    "plt.title('Normalized Importance of Each Skeleton Key Point')\n",
    "plt.xlabel('Skeleton Key Point Index')\n",
    "plt.ylabel('Normalized Decrease in Accuracy')\n",
    "plt.xticks(ticks=range(len(keypoint_names)), labels=keypoint_names, rotation=90)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Normalized Keypoint Importance for all of models keypoints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the input weights to the LSTM layer (76, 128)\n",
    "lstm_layer = model.layers[0]\n",
    "weights = lstm_layer.get_weights()[0]\n",
    "\n",
    "# Sum the absolute values of weights for each of the 76 input features\n",
    "feature_importance = np.sum(np.abs(weights), axis=1)\n",
    "\n",
    "# Since each keypoint has an x and y coordinate, sum the importances for the x and y of each keypoint\n",
    "keypoint_importances = np.array([np.sum(feature_importance[i*2:i*2+2]) for i in range(38)])\n",
    "\n",
    "# Normalize the importances to make them relative\n",
    "normalized_importances = keypoint_importances / np.sum(keypoint_importances)\n",
    "\n",
    "# Plotting\n",
    "plt.figure(figsize=(20, 8))\n",
    "keypoint_names = [f'{i}' for i in range(38)]  # Replace with actual keypoint names if available\n",
    "plt.bar(keypoint_names, normalized_importances)\n",
    "plt.title('Normalized Importance of Each Skeleton Key Point')\n",
    "plt.xlabel('Skeleton Key Points')\n",
    "plt.ylabel('Normalized Importance')\n",
    "plt.xticks(rotation=90)  # Rotate x-axis labels for better readability\n",
    "plt.tight_layout()  # Adjust layout so everything fits without overlapping\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example of manually modifying a single feature across all samples\n",
    "test_input = copy.deepcopy(X_test)\n",
    "test_input[:, :, 0] += 1.0  # Add a constant value to the first feature across all samples\n",
    "altered_predictions = model.predict(test_input)\n",
    "altered_accuracy = compute_accuracy(altered_predictions, y_test)\n",
    "print(\"Original Accuracy:\", original_accuracy)\n",
    "print(\"Altered Accuracy:\", altered_accuracy)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Framework for generating conf matrix,accuracy score and f1 score of an observed test of the system"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix, accuracy_score, f1_score, multilabel_confusion_matrix\n",
    "import seaborn as sns\n",
    "\n",
    "# TEST2.mp4\n",
    "predictions = [\n",
    "    0, 2, 0, 2, 0, 2, 0, 2, 0, 2, 0, 2, 0, 2, 0, 2, 0, 2, 0, 2,\n",
    "    1, 2, 2, 2, 1, 2, 1, 2, 0, 2, 2, 2, 1, 2, 1, 2, 2, 2, 1, 2,\n",
    "    1, 2, 1, 2, 1, 2, 1, 2, 0, 2, 2, 2, 1, 2, 1, 2, 1, 2, 1, 2,\n",
    "    1, 2, 1, 2, 0, 2, 0, 2, 0, 2, 0, 2, 1, 2, 1, 2, 0, 2, 1, 2\n",
    "]\n",
    "true_labels = [\n",
    "    0, 2, 0, 2, 0, 2, 0, 2, 0, 2, 0, 2, 0, 2, 0, 2, 0, 2, 0, 2,\n",
    "    1, 2, 1, 2, 1, 2, 1, 2, 1, 2, 1, 2, 1, 2, 1, 2, 1, 2, 1, 2,\n",
    "    1, 2, 1, 2, 1, 2, 1, 2, 0, 2, 1, 2, 1, 2, 1, 2, 1, 2, 0, 2,\n",
    "    1, 2, 1, 2, 0, 2, 0, 2, 0, 2, 0, 2, 1, 2, 1, 2, 0, 2, 1, 2\n",
    "]\n",
    "\n",
    "# Ensure the number of values is 80\n",
    "assert len(predictions) == 80\n",
    "assert len(true_labels) == 80\n",
    "\n",
    "# Split the labels and predictions into three groups\n",
    "true_labels_1 = true_labels[:20]  # First 20 for Boxing and Nonfighting\n",
    "predictions_1 = predictions[:20]\n",
    "\n",
    "true_labels_2 = true_labels[20:40]  # Next 20 for Kick and Nonfighting\n",
    "predictions_2 = predictions[20:40]\n",
    "\n",
    "true_labels_3 = true_labels[40:]  # Last 40 for mixed (Boxing to Kick)\n",
    "predictions_3 = predictions[40:]\n",
    "\n",
    "# Compute confusion matrices\n",
    "cm1 = confusion_matrix(true_labels_1, predictions_1, labels=[0, 1, 2])\n",
    "cm2 = confusion_matrix(true_labels_2, predictions_2, labels=[0, 1, 2])\n",
    "cm3 = confusion_matrix(true_labels_3, predictions_3, labels=[0, 1, 2])\n",
    "\n",
    "# Compute performance metrics\n",
    "def compute_metrics(cm):\n",
    "    true_labels = []\n",
    "    predicted_labels = []\n",
    "    for i in range(len(cm)):\n",
    "        for j in range(len(cm[i])):\n",
    "            true_labels.extend([i] * cm[i][j])\n",
    "            predicted_labels.extend([j] * cm[i][j])\n",
    "    accuracy = accuracy_score(true_labels, predicted_labels)\n",
    "    f1 = f1_score(true_labels, predicted_labels, average='weighted')\n",
    "    return accuracy, f1\n",
    "\n",
    "accuracy1, f1_1 = compute_metrics(cm1)\n",
    "accuracy2, f1_2 = compute_metrics(cm2)\n",
    "accuracy3, f1_3 = compute_metrics(cm3)\n",
    "\n",
    "avg_accuracy = np.mean([accuracy1, accuracy2, accuracy3])\n",
    "avg_f1_score = np.mean([f1_1, f1_2, f1_3])\n",
    "\n",
    "# Print the averaged performance metrics\n",
    "print(f\"Average Accuracy: {avg_accuracy:.2f}\")\n",
    "print(f\"Average F1 Score: {avg_f1_score:.2f}\")\n",
    "\n",
    "# Plot confusion matrices\n",
    "def plot_confusion_matrix(cm, title):\n",
    "    actions = ['Boxing', 'Kick', 'Nonfighting']\n",
    "    plt.figure(figsize=(6, 5))\n",
    "    sns.heatmap(cm, annot=True, fmt=\"d\", cmap=\"viridis\", xticklabels=actions, yticklabels=actions, annot_kws={\"size\": 16})\n",
    "    plt.xlabel('Predicted label', fontsize=14)\n",
    "    plt.ylabel('True label', fontsize=14)\n",
    "    plt.title(title, fontsize=16)\n",
    "    plt.xticks(fontsize=12)\n",
    "    plt.yticks(fontsize=12)\n",
    "    plt.show()\n",
    "\n",
    "plot_confusion_matrix(cm1, 'Confusion Matrix 1 (Boxing and Nonfighting)')\n",
    "plot_confusion_matrix(cm2, 'Confusion Matrix 2 (Kick and Nonfighting)')\n",
    "plot_confusion_matrix(cm3, 'Confusion Matrix 3 (Mixed Boxing and Kick)')\n",
    "\n",
    "# Generate the multilabel confusion matrix\n",
    "conf_matrix = multilabel_confusion_matrix(true_labels, predictions)\n",
    "accuracy = accuracy_score(true_labels, predictions)\n",
    "f1 = f1_score(true_labels, predictions, average='weighted')\n",
    "\n",
    "print(\"Overall Accuracy: {:.2f}\".format(accuracy))\n",
    "print(\"Overall F1 Score: {:.2f}\".format(f1))\n",
    "print(conf_matrix)\n",
    "\n",
    "# Plot the multilabel confusion matrices\n",
    "def plot_multilabel_confusion_matrix(conf_matrix):\n",
    "    labels = ['Boxing', 'Kick', 'Nonfighting']\n",
    "    for i, cm in enumerate(conf_matrix):\n",
    "        plt.figure(figsize=(6, 5))\n",
    "        sns.heatmap(cm, annot=True, fmt=\"d\", cmap=\"viridis\", xticklabels=['No', 'Yes'], yticklabels=['No', 'Yes'], annot_kws={\"size\": 16})\n",
    "        plt.xlabel('Predicted', fontsize=14)\n",
    "        plt.ylabel('True', fontsize=14)\n",
    "        plt.title(f'Confusion Matrix for {labels[i]}', fontsize=16)\n",
    "        plt.xticks(fontsize=12)\n",
    "        plt.yticks(fontsize=12)\n",
    "        plt.show()\n",
    "\n",
    "plot_multilabel_confusion_matrix(conf_matrix)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "yhat = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ytrue = np.argmax(y_test, axis=1).tolist()\n",
    "yhat = np.argmax(yhat, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "multilabel_confusion_matrix(ytrue, yhat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy_score(ytrue, yhat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_true = true_labels  \n",
    "y_pred = predictions  \n",
    "\n",
    "f1 = f1_score(y_true, y_pred, average='weighted')\n",
    "print(f1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 8. Test in real time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "colors = [(245,117,16), (117,245,16), (16,117,245)]\n",
    "def prob_viz(res, actions, input_frame, colors):\n",
    "    output_frame = input_frame.copy()\n",
    "    for num, prob in enumerate(res):\n",
    "        if num < len(colors):  # Check if the index is within the range of colors\n",
    "            cv2.rectangle(output_frame, (0,60+num*40), (int(prob*100), 90+num*40), colors[num], -1)\n",
    "            cv2.putText(output_frame, actions[num], (0, 85+num*40), cv2.FONT_HERSHEY_SIMPLEX, 1, (255,255,255), 2, cv2.LINE_AA)\n",
    "        \n",
    "    return output_frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.imshow(cv2.cvtColor(prob_viz(model.predict(X_test)[0], actions, np.zeros((100,100,3), dtype=np.uint8), colors), cv2.COLOR_BGR2RGB))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " # Create a Camera object\n",
    "zed = sl.Camera()\n",
    "\n",
    "# Create a InitParameters object and set configuration parameters\n",
    "init_params = sl.InitParameters()\n",
    "#init_params.camera_resolution = sl.RESOLUTION.HD720  # Use HD720 video mode\n",
    "init_params.depth_mode = sl.DEPTH_MODE.PERFORMANCE\n",
    "init_params.coordinate_units = sl.UNIT.METER\n",
    "init_params.sdk_verbose = 1\n",
    "\n",
    "init_params.camera_resolution = sl.RESOLUTION.HD1080\n",
    "init_params.camera_fps = 30\n",
    "\n",
    "\n",
    "# Open the camera\n",
    "err = zed.open(init_params)\n",
    "if err != sl.ERROR_CODE.SUCCESS:\n",
    "    print(\"Camera Open : \"+repr(err)+\". Exit program.\")\n",
    "    exit()\n",
    "\n",
    "body_params = sl.BodyTrackingParameters()\n",
    "# Different model can be chosen, optimizing the runtime or the accuracy\n",
    "body_params.detection_model = sl.BODY_TRACKING_MODEL.HUMAN_BODY_FAST\n",
    "body_params.enable_tracking = True\n",
    "body_params.image_sync = True\n",
    "body_params.enable_segmentation = False\n",
    "# Optimize the person joints position, requires more computations\n",
    "body_params.enable_body_fitting = True\n",
    "body_params.body_format = sl.BODY_FORMAT.BODY_38\n",
    "\n",
    "if body_params.enable_tracking:\n",
    "    positional_tracking_param = sl.PositionalTrackingParameters()\n",
    "    # positional_tracking_param.set_as_static = True\n",
    "    positional_tracking_param.set_floor_as_origin = True\n",
    "    zed.enable_positional_tracking(positional_tracking_param)\n",
    "\n",
    "print(\"Body tracking: Loading Module...\")\n",
    "\n",
    "err = zed.enable_body_tracking(body_params)\n",
    "if err != sl.ERROR_CODE.SUCCESS:\n",
    "    print(\"Enable Body Tracking : \"+repr(err)+\". Exit program.\")\n",
    "    zed.close()\n",
    "    exit()\n",
    "bodies = sl.Bodies()\n",
    "body_runtime_param = sl.BodyTrackingRuntimeParameters()\n",
    "# For outdoor scene or long range, the confidence should be lowered to avoid missing detections (~20-30)\n",
    "# For indoor scene or closer range, a higher confidence limits the risk of false positives and increase the precision (~50+)\n",
    "body_runtime_param.detection_confidence_threshold = 40\n",
    "\n",
    "\n",
    "cv2.namedWindow(\"ZED Body Tracking\", cv2.WINDOW_NORMAL)\n",
    "image = sl.Mat()\n",
    "i = 0 \n",
    "\n",
    "cap = cv2.VideoCapture(0)\n",
    "# NEW LOOP\n",
    "# Loop through actions\n",
    "\n",
    "sequencelist = []\n",
    "sentence = []\n",
    "threshold = 0.5\n",
    "\n",
    "\n",
    "\n",
    "while True:\n",
    "        if zed.grab() == sl.ERROR_CODE.SUCCESS:\n",
    "            zed.retrieve_image(image, sl.VIEW.LEFT)  # Get the image\n",
    "            frame = image.get_data()  # Convert to OpenCV format\n",
    "            err = zed.retrieve_bodies(bodies, body_runtime_param)\n",
    "            if bodies.is_new:\n",
    "                body_array = bodies.body_list\n",
    "                \n",
    "                if len(body_array) > 0:\n",
    "\n",
    "\n",
    "                    body = body_array[0]\n",
    "\n",
    "                        \n",
    "                        # Extract 2D keypoints\n",
    "                    keypoint_2d = body.keypoint_2d\n",
    "                    print(\"Keypoints 2D: \" + str(keypoint_2d))\n",
    "                    \n",
    "                    \n",
    "\n",
    "\n",
    "                    # Draw skeleton joints on the image\n",
    "                    draw_skeleton(frame, keypoint_2d)\n",
    "\n",
    "\n",
    "                    frame_copy = frame.copy()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "                    # predict logic\n",
    "                    processed_data = np.array(keypoint_2d).reshape(1, -1)\n",
    "\n",
    "                    sequencelist.append(processed_data)\n",
    "\n",
    "                    sequencelist = sequencelist[-30:]\n",
    "\n",
    "\n",
    "                    sequencelista = np.stack(sequencelist, axis=0)\n",
    "                    sequencelista = np.squeeze(sequencelist, axis=1)\n",
    "                    \n",
    "                    if len(sequencelist) == 30:\n",
    "                        v = np.expand_dims(sequencelista, axis=0)\n",
    "                        res = model.predict(v)[0]\n",
    "                        print(actions[np.argmax(res)])\n",
    "\n",
    "\n",
    "                        if res[np.argmax(res)] > threshold:\n",
    "                            if len(sentence) > 0:\n",
    "                                if actions[np.argmax(res)] != sentence[-1]:\n",
    "                                    sentence.append(actions[np.argmax(res)])\n",
    "                            else:\n",
    "                                sentence.append(actions[np.argmax(res)])\n",
    "\n",
    "\n",
    "                        \n",
    "                        if len(sentence) > 1:\n",
    "                            sentence = sentence[-1:]\n",
    "                        # Show the sentence text\n",
    "\n",
    "                        frame_copy = prob_viz(res, actions, frame_copy, colors)\n",
    "                        \n",
    "                        sentence_text = ' '.join(sentence)\n",
    "                        cv2.putText(frame_copy,sentence_text, (10, 30), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 0, 0), 2)\n",
    "                        \n",
    "                        cv2.rectangle(frame_copy, (0, 0), (640, 40), (0, 255, 0), 2)\n",
    "\n",
    "                    \n",
    "                        # Show to screen\n",
    "                        cv2.imshow('OpenCV Feed', frame_copy)\n",
    "\n",
    "                    \n",
    "            #cv2.imshow(\"ZED Body Tracking\", frame)\n",
    "            \n",
    "            if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "                break\n",
    "# Close the camera\n",
    "zed.disable_body_tracking()\n",
    "zed.close()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 9. Generate .onnx file for model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install tf2onnx\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import load_model\n",
    "\n",
    "# Load the Keras model from the HDF5 file\n",
    "model = load_model('mainModel.h5')\n",
    "\n",
    "import tf2onnx\n",
    "import tensorflow as tf\n",
    "\n",
    "# The input name and shape can vary depending on your model's architecture\n",
    "# For example, if your model's input layer name is 'input_1' and expects input of size (224, 224, 3), specify that here\n",
    "input_spec = [tf.TensorSpec((None, 30, 76), tf.float32, name=\"input\")]\n",
    "\n",
    "# Convert the model\n",
    "onnx_model, _ = tf2onnx.convert.from_keras(model, input_signature=input_spec, opset=13)\n",
    "\n",
    "# Save the ONNX model to a file\n",
    "onnx_file_name = \"modelfunkar.onnx\"\n",
    "with open(onnx_file_name, \"wb\") as f:\n",
    "    f.write(onnx_model.SerializeToString())\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "bodytrack",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
